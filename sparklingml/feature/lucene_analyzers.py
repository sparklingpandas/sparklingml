#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# DO NOT MODIFY THIS FILE!
# It was auto generated by LuceneanalyzerGenerators

from __future__ import unicode_literals

from pyspark import keyword_only
from pyspark.ml.param import *
from pyspark.ml.param.shared import *
# The shared params aren't really intended to be public currently..
from pyspark.ml.param.shared import HasInputCol, HasOutputCol
from pyspark.ml.util import *

from sparklingml.java_wrapper_ml import *
from sparklingml.param.shared import HasStopwordCase, HasStopwords


class ArabicAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ArabicAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ArabicAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    ArabicAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ArabicAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(ArabicAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class BulgarianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BulgarianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    BulgarianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    BulgarianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BulgarianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(BulgarianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class BrazilianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BrazilianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    BrazilianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    BrazilianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BrazilianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(BrazilianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class CatalanAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CatalanAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    CatalanAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    CatalanAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CatalanAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(CatalanAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class CJKAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CJKAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    CJKAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    CJKAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CJKAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(CJKAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class SoraniAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SoraniAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    SoraniAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    SoraniAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SoraniAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(SoraniAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class SmartChineseAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SmartChineseAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    SmartChineseAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SmartChineseAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(SmartChineseAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class KeywordAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = KeywordAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    KeywordAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "KeywordAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(KeywordAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class SimpleAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SimpleAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    SimpleAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SimpleAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(SimpleAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class StopAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = StopAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    StopAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    StopAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "StopAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(StopAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class UnicodeWhitespaceAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = UnicodeWhitespaceAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    UnicodeWhitespaceAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "UnicodeWhitespaceAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(UnicodeWhitespaceAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class WhitespaceAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = WhitespaceAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    WhitespaceAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "WhitespaceAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(WhitespaceAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class CzechAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = CzechAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    CzechAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    CzechAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "CzechAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(CzechAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class DanishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = DanishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    DanishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    DanishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "DanishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(DanishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class GermanAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GermanAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    GermanAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    GermanAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GermanAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(GermanAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class GreekAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GreekAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    GreekAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    GreekAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GreekAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(GreekAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class EnglishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = EnglishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    EnglishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    EnglishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "EnglishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(EnglishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class SpanishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SpanishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    SpanishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    SpanishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> result.head()
    Row(vals=u'hi boo', out=[u'hi', u'boo'])
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SpanishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(SpanishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class BasqueAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = BasqueAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    BasqueAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    BasqueAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "BasqueAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(BasqueAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class PersianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = PersianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    PersianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    PersianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "PersianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(PersianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class FinnishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = FinnishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    FinnishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    FinnishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "FinnishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(FinnishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class FrenchAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = FrenchAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    FrenchAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    FrenchAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "FrenchAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(FrenchAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class IrishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = IrishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    IrishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    IrishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "IrishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(IrishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class GalicianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = GalicianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    GalicianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    GalicianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "GalicianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(GalicianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class HindiAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = HindiAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    HindiAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    HindiAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "HindiAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(HindiAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class HungarianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = HungarianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    HungarianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    HungarianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "HungarianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(HungarianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class ArmenianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ArmenianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ArmenianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    ArmenianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ArmenianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(ArmenianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class IndonesianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = IndonesianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    IndonesianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    IndonesianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "IndonesianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(IndonesianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class ItalianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ItalianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ItalianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    ItalianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ItalianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(ItalianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class JapaneseAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = JapaneseAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    JapaneseAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "JapaneseAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(JapaneseAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class LithuanianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = LithuanianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    LithuanianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    LithuanianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "LithuanianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(LithuanianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class LatvianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = LatvianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    LatvianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    LatvianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "LatvianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(LatvianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class MorfologikAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = MorfologikAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    MorfologikAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "MorfologikAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(MorfologikAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class DutchAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = DutchAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    DutchAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "DutchAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(DutchAnalyzerLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class NorwegianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = NorwegianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    NorwegianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    NorwegianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "NorwegianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(NorwegianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class PolishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = PolishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    PolishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    PolishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "PolishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(PolishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class PortugueseAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = PortugueseAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    PortugueseAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    PortugueseAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "PortugueseAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(PortugueseAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class RomanianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = RomanianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    RomanianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    RomanianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "RomanianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(RomanianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class RussianAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = RussianAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    RussianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    RussianAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "RussianAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(RussianAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class ShingleAnalyzerWrapperLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ShingleAnalyzerWrapperLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ShingleAnalyzerWrapperLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ShingleAnalyzerWrapperLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None):
        """
        __init__(self, inputCol=None, outputCol=None)
        """
        super(ShingleAnalyzerWrapperLucene, self).__init__()
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None):
        """
        setParams(inputCol=None, outputCol=None)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class ClassicAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ClassicAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ClassicAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    ClassicAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ClassicAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(ClassicAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class StandardAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = StandardAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    StandardAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    StandardAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "StandardAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(StandardAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class UAX29URLEmailAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = UAX29URLEmailAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    UAX29URLEmailAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    UAX29URLEmailAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "UAX29URLEmailAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(UAX29URLEmailAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class SwedishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = SwedishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    SwedishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    SwedishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "SwedishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(SwedishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class ThaiAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = ThaiAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    ThaiAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    ThaiAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "ThaiAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(ThaiAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class TurkishAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = TurkishAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    TurkishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    TurkishAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "TurkishAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(TurkishAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


class UkrainianMorfologikAnalyzerLucene(
        SparklingJavaTransformer, HasInputCol, HasOutputCol,
        HasStopwords, HasStopwordCase):
    """
    >>> from pyspark.sql import SparkSession
    >>> spark = SparkSession.builder.master("local[2]").getOrCreate()
    >>> df = spark.createDataFrame([("hi boo",), ("bye boo",)], ["vals"])
    >>> transformer = UkrainianMorfologikAnalyzerLucene()
    >>> transformer.setParams(inputCol="vals", outputCol="out")
    UkrainianMorfologikAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    >>> transformer.setStopwordCase(True)
    UkrainianMorfologikAnalyzerLucene_...
    >>> result = transformer.transform(df)
    >>> result.count()
    2
    """
    package_name = "com.sparklingpandas.sparklingml.feature"
    class_name = "UkrainianMorfologikAnalyzerLucene"
    transformer_name = package_name + "." + class_name

    @keyword_only
    def __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False):
        """
        __init__(self, inputCol=None, outputCol=None,
                 stopwords=None, stopwordCase=False)
        """
        super(UkrainianMorfologikAnalyzerLucene, self).__init__()
        self._setDefault(stopwordCase=False)
        kwargs = self._input_kwargs
        self.setParams(**kwargs)

    @keyword_only
    def setParams(self, inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False):
        """
        setParams(inputCol=None, outputCol=None,
                  stopwords=None, stopwordCase=False)
        """
        kwargs = self._input_kwargs
        return self._set(**kwargs)


if __name__ == "__main__":
    import doctest
    doctest.testmod(optionflags=doctest.ELLIPSIS)
